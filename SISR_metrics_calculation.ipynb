{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YKQqG9cUR-X"
      },
      "source": [
        "# Super-Resolution metrics calculation\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "611GG7eXUR-b"
      },
      "source": [
        "# 1. **Install dependencies**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVHyiwkjUR-b"
      },
      "source": [
        "## 1.1. **Install key dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lGUSExhlR5tT"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Install NumPy 1.26.0\n",
        "#@markdown After running this cell, your session will be automatically restarted for the changes to take effect.\n",
        "\n",
        "import importlib.metadata\n",
        "\n",
        "desired_version = \"1.26.0\"\n",
        "\n",
        "try:\n",
        "    installed_version = importlib.metadata.version(\"numpy\")\n",
        "    if installed_version == desired_version:\n",
        "        print(f\"NumPy {desired_version} is already installed.\")\n",
        "    else:\n",
        "        print(f\"Installing NumPy {desired_version} (current: {installed_version})...\")\n",
        "        !pip install numpy=={desired_version} --prefer-binary\n",
        "        import os\n",
        "        os._exit(00)  # Restart runtime for changes to take effect\n",
        "except importlib.metadata.PackageNotFoundError:\n",
        "    print(f\"NumPy is not installed. Installing {desired_version}...\")\n",
        "    !pip install numpy=={desired_version} --prefer-binary\n",
        "    import os\n",
        "    os._exit(00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eSiQ7uumR3Es"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Install the rest of packages\n",
        "#@markdown After running this cell, your session will be automatically restarted for the changes to take effect.\n",
        "\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip cache purge\n",
        "!pip install -q torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1\n",
        "\n",
        "!pip install -q nbformat==5.10.4\n",
        "!pip install -q plotly==6.0.1\n",
        "!pip install -q torchmetrics[image]==1.4.0\n",
        "!pip install -q torch-fidelity==0.3.0\n",
        "!pip install -q nanopyx==1.1.0\n",
        "!pip install -q pandas==2.2.2\n",
        "!pip install -q matplotlib==3.8.0\n",
        "!pip install -q opencv-python==4.8.0.76\n",
        "\n",
        "print(\"Everything correctly installed, your session will be automatically restarted to activate the changes.\")\n",
        "\n",
        "import os\n",
        "os._exit(00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA9ovBWnUR-c"
      },
      "source": [
        "## 1.2. **Load key dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EudZQ0mkUR-d"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Load key dependencies\n",
        "\n",
        "import os\n",
        "#Create a variable to get and store relative base path\n",
        "base_path = os.getcwd()\n",
        "\n",
        "# Load PyTorch\n",
        "import torch\n",
        "\n",
        "# Load the torchmetrics functions\n",
        "from torchmetrics.regression import MeanSquaredError, MeanAbsoluteError\n",
        "from torchmetrics.image import PeakSignalNoiseRatio\n",
        "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity\n",
        "\n",
        "# Load the NanoPyx functions\n",
        "from nanopyx.core.analysis.decorr import DecorrAnalysis\n",
        "from nanopyx.core.transform import ErrorMap\n",
        "\n",
        "# Load the functions to calculate IL-NIQE\n",
        "from scipy.ndimage.filters import convolve\n",
        "from scipy.signal import convolve2d\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import exponweib\n",
        "from scipy.optimize import fmin\n",
        "import scipy.io\n",
        "\n",
        "# Load other packages\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage import io\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import cv2\n",
        "import math\n",
        "import os\n",
        "\n",
        "# Load the packages for final plot\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Define the main functions\n",
        "def print_img_info(img, description=\"\", is_dir=False):\n",
        "    print(f\"{description}\")\n",
        "\n",
        "    if isinstance(img, list):\n",
        "        print(\"Stack of images with different shape.\")\n",
        "\n",
        "        img_shapes, img_types, img_min, img_max, img_means, img_stds = [], [], [], [], [], []\n",
        "\n",
        "        for i, image in enumerate(img):\n",
        "            img_shapes.append(image.shape)\n",
        "            img_types.append(image.dtype)\n",
        "            img_min.append(image.min())\n",
        "            img_max.append(image.max())\n",
        "            img_means.append(image.mean())\n",
        "            img_stds.append(image.std())\n",
        "\n",
        "        print(f\"\\tShapes: {np.unique(img_shapes)}\")\n",
        "        print(f\"\\tTypes: {np.unique(img_types)}\")\n",
        "        print(f\"\\tMinimum values: {np.mean(img_min)} ± {np.std(img_min)}\")\n",
        "        print(f\"\\tMaximum values: {np.mean(img_max)} ± {np.std(img_max)}\")\n",
        "        print(f\"\\tMean values: {np.mean(img_means)} ± {np.std(img_means)}\")\n",
        "        print(f\"\\tStandard deviations: {np.mean(img_stds)} ± {np.std(img_stds)}\")\n",
        "\n",
        "    elif isinstance(img, np.ndarray):\n",
        "        if is_dir:\n",
        "            print(\"Stack of NumPy images with the same shape.\")\n",
        "        else:\n",
        "            print(\"Single NumPy image.\")\n",
        "\n",
        "        print(f\"\\tShape: {img.shape}\")\n",
        "        print(f\"\\tType: {img.dtype}\")\n",
        "        print(f\"\\tRange of values:[{img.min()},{img.max()}]\")\n",
        "        print(f\"\\tMean±Std:{img.mean():.3f}±{img.std():.3f}\")\n",
        "    elif isinstance(img, torch.Tensor):\n",
        "        if is_dir:\n",
        "            print(\"Stack of PyTorch Tensor images with the same shape.\")\n",
        "        else:\n",
        "            print(\"Single PyTorch Tensor image.\")\n",
        "\n",
        "        print(f\"\\tShape: {img.shape}\")\n",
        "        print(f\"\\tType: {img.dtype}\")\n",
        "        print(f\"\\tRange of values:[{img.min()},{img.max()}]\")\n",
        "        print(f\"\\tMean±Std:{img.mean():.3f}±{img.std():.3f}\")\n",
        "    else:\n",
        "        raise ValueError(\"Image must be a list or a numpy array.\")\n",
        "\n",
        "    print(\"------\")\n",
        "\n",
        "def load_images(path, normalize=\"None\"):\n",
        "\n",
        "    # Load the images\n",
        "    if os.path.isdir(path):\n",
        "        filename_list = []\n",
        "        images_list = []\n",
        "\n",
        "        for filename in sorted(os.listdir(path)):\n",
        "            filename_list.append(filename)\n",
        "\n",
        "            if normalize == \"None\" or normalize == \"Across all images\":\n",
        "                images_list.append(io.imread(os.path.join(path, filename)))\n",
        "            elif normalize == \"Per image\":\n",
        "                images_list.append(min_max_norm_numpy(io.imread(os.path.join(path, filename))))\n",
        "\n",
        "        try:\n",
        "            images_list = np.array(images_list)\n",
        "        except:\n",
        "            print(\"WARNING: The images in the folder are not of the same size.\")\n",
        "\n",
        "        if normalize == \"Across all images\":\n",
        "            images_list = min_max_norm(images_list)\n",
        "\n",
        "        return images_list, filename_list\n",
        "    else:\n",
        "        if normalize == \"None\":\n",
        "            image = io.imread(path)\n",
        "        else:\n",
        "            image = min_max_norm_numpy(io.imread(path))\n",
        "\n",
        "        return image, path\n",
        "\n",
        "def min_max_norm(data):\n",
        "    # Check if the data is a list or a numpy array\n",
        "    if isinstance(data, list):\n",
        "        return min_max_norm_list(data)\n",
        "    elif isinstance(data, np.ndarray):\n",
        "        return min_max_norm_numpy(data)\n",
        "    else:\n",
        "        raise ValueError(\"Input data must be a list or a numpy array.\")\n",
        "\n",
        "def min_max_norm_numpy(data):\n",
        "    return (data - data.min())/(data.max() - data.min() + 1e-10)\n",
        "\n",
        "def min_max_norm_list(data):\n",
        "    # Get the minimum and maximum values of the list\n",
        "    min_val = min([img.min() for img in data])\n",
        "    max_val = max([img.max() for img in data])\n",
        "\n",
        "    # Normalize each image in the list\n",
        "    normalized_data = [(img - min_val) / (max_val - min_val + 1e-10) for img in data]\n",
        "\n",
        "    return normalized_data\n",
        "\n",
        "#####\n",
        "\n",
        "def get_size_from_scale(input_size, scale_factor):\n",
        "    \"\"\"Get the output size given input size and scale factor.\n",
        "    Args:\n",
        "        input_size (tuple): The size of the input image.\n",
        "        scale_factor (float): The resize factor.\n",
        "    Returns:\n",
        "        list[int]: The size of the output image.\n",
        "    \"\"\"\n",
        "\n",
        "    output_shape = [\n",
        "        int(np.ceil(scale * shape))\n",
        "        for (scale, shape) in zip(scale_factor, input_size)\n",
        "    ]\n",
        "\n",
        "    return output_shape\n",
        "\n",
        "\n",
        "def get_scale_from_size(input_size, output_size):\n",
        "    \"\"\"Get the scale factor given input size and output size.\n",
        "    Args:\n",
        "        input_size (tuple(int)): The size of the input image.\n",
        "        output_size (tuple(int)): The size of the output image.\n",
        "    Returns:\n",
        "        list[float]: The scale factor of each dimension.\n",
        "    \"\"\"\n",
        "\n",
        "    scale = [\n",
        "        1.0 * output_shape / input_shape\n",
        "        for (input_shape, output_shape) in zip(input_size, output_size)\n",
        "    ]\n",
        "\n",
        "    return scale\n",
        "\n",
        "\n",
        "def _cubic(x):\n",
        "    \"\"\" Cubic function.\n",
        "    Args:\n",
        "        x (ndarray): The distance from the center position.\n",
        "    Returns:\n",
        "        ndarray: The weight corresponding to a particular distance.\n",
        "    \"\"\"\n",
        "\n",
        "    x = np.array(x, dtype=np.float32)\n",
        "    x_abs = np.abs(x)\n",
        "    x_abs_sq = x_abs**2\n",
        "    x_abs_cu = x_abs_sq * x_abs\n",
        "\n",
        "    # if |x| <= 1: y = 1.5|x|^3 - 2.5|x|^2 + 1\n",
        "    # if 1 < |x| <= 2: -0.5|x|^3 + 2.5|x|^2 - 4|x| + 2\n",
        "    f = (1.5 * x_abs_cu - 2.5 * x_abs_sq + 1) * (x_abs <= 1) + (\n",
        "        -0.5 * x_abs_cu + 2.5 * x_abs_sq - 4 * x_abs + 2) * ((1 < x_abs) &\n",
        "                                                             (x_abs <= 2))\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def get_weights_indices(input_length, output_length, scale, kernel,\n",
        "                        kernel_width):\n",
        "    \"\"\"Get weights and indices for interpolation.\n",
        "    Args:\n",
        "        input_length (int): Length of the input sequence.\n",
        "        output_length (int): Length of the output sequence.\n",
        "        scale (float): Scale factor.\n",
        "        kernel (func): The kernel used for resizing.\n",
        "        kernel_width (int): The width of the kernel.\n",
        "    Returns:\n",
        "        list[ndarray]: The weights and the indices for interpolation.\n",
        "    \"\"\"\n",
        "    if scale < 1:  # modified kernel for antialiasing\n",
        "\n",
        "        def h(x):\n",
        "            return scale * kernel(scale * x)\n",
        "\n",
        "        kernel_width = 1.0 * kernel_width / scale\n",
        "    else:\n",
        "        h = kernel\n",
        "        kernel_width = kernel_width\n",
        "\n",
        "    # coordinates of output\n",
        "    x = np.arange(1, output_length + 1).astype(np.float32)\n",
        "\n",
        "    # coordinates of input\n",
        "    u = x / scale + 0.5 * (1 - 1 / scale)\n",
        "    left = np.floor(u - kernel_width / 2)  # leftmost pixel\n",
        "    p = int(np.ceil(kernel_width)) + 2  # maximum number of pixels\n",
        "\n",
        "    # indices of input pixels\n",
        "    ind = left[:, np.newaxis, ...] + np.arange(p)\n",
        "    indices = ind.astype(np.int32)\n",
        "\n",
        "    # weights of input pixels\n",
        "    weights = h(u[:, np.newaxis, ...] - indices - 1)\n",
        "\n",
        "    weights = weights / np.sum(weights, axis=1)[:, np.newaxis, ...]\n",
        "\n",
        "    # remove all-zero columns\n",
        "    aux = np.concatenate(\n",
        "        (np.arange(input_length), np.arange(input_length - 1, -1,\n",
        "                                            step=-1))).astype(np.int32)\n",
        "    indices = aux[np.mod(indices, aux.size)]\n",
        "    ind2store = np.nonzero(np.any(weights, axis=0))\n",
        "    weights = weights[:, ind2store]\n",
        "    indices = indices[:, ind2store]\n",
        "\n",
        "    return weights, indices\n",
        "\n",
        "\n",
        "def resize_along_dim(img_in, weights, indices, dim):\n",
        "    \"\"\"Resize along a specific dimension.\n",
        "    Args:\n",
        "        img_in (ndarray): The input image.\n",
        "        weights (ndarray): The weights used for interpolation, computed from\n",
        "            [get_weights_indices].\n",
        "        indices (ndarray): The indices used for interpolation, computed from\n",
        "            [get_weights_indices].\n",
        "        dim (int): Which dimension to undergo interpolation.\n",
        "    Returns:\n",
        "        ndarray: Interpolated (along one dimension) image.\n",
        "    \"\"\"\n",
        "\n",
        "    img_in = img_in.astype(np.float32)\n",
        "    w_shape = weights.shape\n",
        "    output_shape = list(img_in.shape)\n",
        "    output_shape[dim] = w_shape[0]\n",
        "    img_out = np.zeros(output_shape)\n",
        "\n",
        "    if dim == 0:\n",
        "        for i in range(w_shape[0]):\n",
        "            w = weights[i, :][np.newaxis, ...]\n",
        "            ind = indices[i, :]\n",
        "            img_slice = img_in[ind, :]\n",
        "            img_out[i] = np.sum(np.squeeze(img_slice, axis=0) * w.T, axis=0)\n",
        "    elif dim == 1:\n",
        "        for i in range(w_shape[0]):\n",
        "            w = weights[i, :][:, :, np.newaxis]\n",
        "            ind = indices[i, :]\n",
        "            img_slice = img_in[:, ind]\n",
        "            img_out[:, i] = np.sum(np.squeeze(img_slice, axis=1) * w.T, axis=1)\n",
        "\n",
        "    if img_in.dtype == np.uint8:\n",
        "        img_out = np.clip(img_out, 0, 255)\n",
        "        return np.around(img_out).astype(np.uint8)\n",
        "    else:\n",
        "        return img_out\n",
        "\n",
        "\n",
        "class MATLABLikeResize:\n",
        "    \"\"\"Resize the input image using MATLAB-like downsampling.\n",
        "        Currently support bicubic interpolation only. Note that the output of\n",
        "        this function is slightly different from the official MATLAB function.\n",
        "        Required keys are the keys in attribute \"keys\". Added or modified keys\n",
        "        are \"scale\" and \"output_shape\", and the keys in attribute \"keys\".\n",
        "        Args:\n",
        "            keys (list[str]): A list of keys whose values are modified.\n",
        "            scale (float | None, optional): The scale factor of the resize\n",
        "                operation. If None, it will be determined by output_shape.\n",
        "                Default: None.\n",
        "            output_shape (tuple(int) | None, optional): The size of the output\n",
        "                image. If None, it will be determined by scale. Note that if\n",
        "                scale is provided, output_shape will not be used.\n",
        "                Default: None.\n",
        "            kernel (str, optional): The kernel for the resize operation.\n",
        "                Currently support 'bicubic' only. Default: 'bicubic'.\n",
        "            kernel_width (float): The kernel width. Currently support 4.0 only.\n",
        "                Default: 4.0.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 keys=None,\n",
        "                 scale=None,\n",
        "                 output_shape=None,\n",
        "                 kernel='bicubic',\n",
        "                 kernel_width=4.0):\n",
        "\n",
        "        if kernel.lower() != 'bicubic':\n",
        "            raise ValueError('Currently support bicubic kernel only.')\n",
        "\n",
        "        if float(kernel_width) != 4.0:\n",
        "            raise ValueError('Current support only width=4 only.')\n",
        "\n",
        "        if scale is None and output_shape is None:\n",
        "            raise ValueError('\"scale\" and \"output_shape\" cannot be both None')\n",
        "\n",
        "        self.kernel_func = _cubic\n",
        "        self.keys = keys\n",
        "        self.scale = scale\n",
        "        self.output_shape = output_shape\n",
        "        self.kernel = kernel\n",
        "        self.kernel_width = kernel_width\n",
        "\n",
        "    def resize_img(self, img):\n",
        "        return self._resize(img)\n",
        "\n",
        "    def _resize(self, img):\n",
        "        weights = {}\n",
        "        indices = {}\n",
        "\n",
        "        # compute scale and output_size\n",
        "        if self.scale is not None:\n",
        "            scale = float(self.scale)\n",
        "            scale = [scale, scale]\n",
        "            output_size = get_size_from_scale(img.shape, scale)\n",
        "        else:\n",
        "            scale = get_scale_from_size(img.shape, self.output_shape)\n",
        "            output_size = list(self.output_shape)\n",
        "\n",
        "        # apply cubic interpolation along two dimensions\n",
        "        order = np.argsort(np.array(scale))\n",
        "        for k in range(2):\n",
        "            key = (img.shape[k], output_size[k], scale[k], self.kernel_func,\n",
        "                   self.kernel_width)\n",
        "            weight, index = get_weights_indices(img.shape[k], output_size[k],\n",
        "                                                scale[k], self.kernel_func,\n",
        "                                                self.kernel_width)\n",
        "            weights[key] = weight\n",
        "            indices[key] = index\n",
        "\n",
        "        output = np.copy(img)\n",
        "        if output.ndim == 2:  # grayscale image\n",
        "            output = output[:, :, np.newaxis]\n",
        "\n",
        "        for k in range(2):\n",
        "            dim = order[k]\n",
        "            key = (img.shape[dim], output_size[dim], scale[dim],\n",
        "                   self.kernel_func, self.kernel_width)\n",
        "            output = resize_along_dim(output, weights[key], indices[key], dim)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def __call__(self, results):\n",
        "        for key in self.keys:\n",
        "            is_single_image = False\n",
        "            if isinstance(results[key], np.ndarray):\n",
        "                is_single_image = True\n",
        "                results[key] = [results[key]]\n",
        "\n",
        "            results[key] = [self._resize(img) for img in results[key]]\n",
        "\n",
        "            if is_single_image:\n",
        "                results[key] = results[key][0]\n",
        "\n",
        "        results['scale'] = self.scale\n",
        "        results['output_shape'] = self.output_shape\n",
        "\n",
        "        return results\n",
        "\n",
        "    def __repr__(self):\n",
        "        repr_str = self.__class__.__name__\n",
        "        repr_str += (\n",
        "            f'(keys={self.keys}, scale={self.scale}, '\n",
        "            f'output_shape={self.output_shape}, '\n",
        "            f'kernel={self.kernel}, kernel_width={self.kernel_width})')\n",
        "        return repr_str\n",
        "\n",
        "\n",
        "def reorder_image(img, input_order='HWC'):\n",
        "    \"\"\"Reorder images to 'HWC' order.\n",
        "    If the input_order is (h, w), return (h, w, 1);\n",
        "    If the input_order is (c, h, w), return (h, w, c);\n",
        "    If the input_order is (h, w, c), return as it is.\n",
        "    Args:\n",
        "        img (ndarray): Input image.\n",
        "        input_order (str): Whether the input order is 'HWC' or 'CHW'.\n",
        "            If the input image shape is (h, w), input_order will not have\n",
        "            effects. Default: 'HWC'.\n",
        "    Returns:\n",
        "        ndarray: reordered image.\n",
        "    \"\"\"\n",
        "\n",
        "    if input_order not in ['HWC', 'CHW']:\n",
        "        raise ValueError(f'Wrong input_order {input_order}. Supported input_orders are ' \"'HWC' and 'CHW'\")\n",
        "    if len(img.shape) == 2:\n",
        "        img = img[..., None]\n",
        "    if input_order == 'CHW':\n",
        "        img = img.transpose(1, 2, 0)\n",
        "    return img\n",
        "\n",
        "def fitweibull(x):\n",
        "   def optfun(theta):\n",
        "      return -np.sum(np.log(exponweib.pdf(x, 1, theta[0], scale = theta[1], loc = 0)))\n",
        "   logx = np.log(x)\n",
        "   shape = 1.2 / np.std(logx)\n",
        "   scale = np.exp(np.mean(logx) + (0.572 / shape))\n",
        "   return fmin(optfun, [shape, scale], xtol = 0.01, ftol = 0.01, disp = 0)\n",
        "\n",
        "def estimate_aggd_param(block):\n",
        "    \"\"\"Estimate AGGD (Asymmetric Generalized Gaussian Distribution) parameters.\n",
        "    Args:\n",
        "        block (ndarray): 2D Image block.\n",
        "    Returns:\n",
        "        tuple: alpha (float), beta_l (float) and beta_r (float) for the AGGD\n",
        "            distribution (Estimating the parames in Equation 7 in the paper).\n",
        "    \"\"\"\n",
        "    block = block.flatten()\n",
        "    gam = np.arange(0.2, 10.001, 0.001)  # len = 9801\n",
        "    gam_reciprocal = np.reciprocal(gam)\n",
        "    r_gam = np.square(gamma(gam_reciprocal * 2)) / (gamma(gam_reciprocal) * gamma(gam_reciprocal * 3))\n",
        "\n",
        "    left_std = np.sqrt(np.mean(block[block < 0]**2))\n",
        "    right_std = np.sqrt(np.mean(block[block > 0]**2))\n",
        "    gammahat = left_std / right_std\n",
        "    rhat = (np.mean(np.abs(block)))**2 / np.mean(block**2)\n",
        "    rhatnorm = (rhat * (gammahat**3 + 1) * (gammahat + 1)) / ((gammahat**2 + 1)**2)\n",
        "    array_position = np.argmin((r_gam - rhatnorm)**2)\n",
        "\n",
        "    alpha = gam[array_position]\n",
        "    beta_l = left_std * np.sqrt(gamma(1 / alpha) / gamma(3 / alpha))\n",
        "    beta_r = right_std * np.sqrt(gamma(1 / alpha) / gamma(3 / alpha))\n",
        "    return (alpha, beta_l, beta_r)\n",
        "\n",
        "\n",
        "def compute_feature(feature_list, block_posi):\n",
        "    \"\"\"Compute features.\n",
        "    Args:\n",
        "        feature_list(list): feature to be processed.\n",
        "        block_posi (turple): the location of 2D Image block.\n",
        "    Returns:\n",
        "        list: Features with length of 234.\n",
        "    \"\"\"\n",
        "    feat = []\n",
        "    data = feature_list[0][block_posi[0]:block_posi[1], block_posi[2]:block_posi[3]]\n",
        "    alpha_data, beta_l_data, beta_r_data = estimate_aggd_param(data)\n",
        "    feat.extend([alpha_data, (beta_l_data + beta_r_data) / 2])\n",
        "    # distortions disturb the fairly regular structure of natural images.\n",
        "    # This deviation can be captured by analyzing the sample distribution of\n",
        "    # the products of pairs of adjacent coefficients computed along\n",
        "    # horizontal, vertical and diagonal orientations.\n",
        "    shifts = [[0, 1], [1, 0], [1, 1], [1, -1]]\n",
        "    for i in range(len(shifts)):\n",
        "        shifted_block = np.roll(data, shifts[i], axis=(0, 1))\n",
        "        alpha, beta_l, beta_r = estimate_aggd_param(data * shifted_block)\n",
        "        # Eq. 8 in NIQE\n",
        "        mean = (beta_r - beta_l) * (gamma(2 / alpha) / gamma(1 / alpha))\n",
        "        feat.extend([alpha, mean, beta_l, beta_r])\n",
        "\n",
        "    for i in range(1,4):\n",
        "        data = feature_list[i][block_posi[0]:block_posi[1], block_posi[2]:block_posi[3]]\n",
        "        shape, scale = fitweibull(data.flatten('F'))\n",
        "        feat.extend([scale, shape])\n",
        "\n",
        "    for i in range(4,7):\n",
        "        data = feature_list[i][block_posi[0]:block_posi[1], block_posi[2]:block_posi[3]]\n",
        "        mu = np.mean(data)\n",
        "        sigmaSquare = np.var(data.flatten('F'))\n",
        "        feat.extend([mu, sigmaSquare])\n",
        "\n",
        "    for i in range(7,85):\n",
        "        data = feature_list[i][block_posi[0]:block_posi[1], block_posi[2]:block_posi[3]]\n",
        "        alpha_data, beta_l_data, beta_r_data = estimate_aggd_param(data)\n",
        "        feat.extend([alpha_data, (beta_l_data + beta_r_data) / 2])\n",
        "\n",
        "    for i in range(85,109):\n",
        "        data = feature_list[i][block_posi[0]:block_posi[1], block_posi[2]:block_posi[3]]\n",
        "        shape, scale = fitweibull(data.flatten('F'))\n",
        "        feat.extend([scale, shape])\n",
        "\n",
        "    return feat\n",
        "\n",
        "def matlab_fspecial(shape=(3,3),sigma=0.5):\n",
        "    \"\"\"\n",
        "    2D gaussian mask - should give the same result as MATLAB's\n",
        "    fspecial('gaussian',[shape],[sigma])\n",
        "    \"\"\"\n",
        "    m,n = [(ss-1.)/2. for ss in shape]\n",
        "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
        "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
        "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
        "    sumh = h.sum()\n",
        "    if sumh != 0:\n",
        "        h /= sumh\n",
        "    return h\n",
        "\n",
        "def gauDerivative(sigma):\n",
        "    halfLength = math.ceil(3*sigma)\n",
        "\n",
        "    x, y = np.meshgrid(np.linspace(-halfLength, halfLength, 2*halfLength+1), np.linspace(-halfLength, halfLength, 2*halfLength+1))\n",
        "\n",
        "    gauDerX = x*np.exp(-(x**2 + y**2)/2/sigma/sigma)\n",
        "    gauDerY = y*np.exp(-(x**2 + y**2)/2/sigma/sigma)\n",
        "\n",
        "    return gauDerX, gauDerY\n",
        "\n",
        "def conv2(x, y, mode='same'):\n",
        "    return np.rot90(convolve2d(np.rot90(x, 2), np.rot90(y, 2), mode=mode), 2)\n",
        "\n",
        "def logGabors(rows, cols, minWaveLength, sigmaOnf, mult, dThetaOnSigma):\n",
        "    nscale          = 3    # Number of wavelet scales.\n",
        "    norient         = 4    # Number of filter orientations.\n",
        "    thetaSigma = math.pi/norient/dThetaOnSigma  # Calculate the standard deviation of the angular Gaussian function used to construct filters in the freq. plane.\n",
        "    if cols % 2 > 0:\n",
        "        xrange = np.linspace(-(cols-1)/2, (cols-1)/2, cols)/(cols-1)\n",
        "    else:\n",
        "        xrange = np.linspace(-cols/2, cols/2-1, cols)/cols\n",
        "\n",
        "    if rows % 2 > 0:\n",
        "        yrange = np.linspace(-(rows-1)/2, (rows-1)/2, rows)/(rows-1)\n",
        "    else:\n",
        "        yrange = np.linspace(-rows/2, rows/2-1, rows)/rows\n",
        "\n",
        "    x, y = np.meshgrid(xrange, yrange)\n",
        "    radius = np.sqrt(x**2 + y**2)\n",
        "    theta = np.arctan2(-y,x)\n",
        "    radius = np.fft.ifftshift(radius)\n",
        "    theta  = np.fft.ifftshift(theta)\n",
        "    radius[0,0] = 1\n",
        "    sintheta = np.sin(theta)\n",
        "    costheta = np.cos(theta)\n",
        "\n",
        "    logGabor = []\n",
        "    for s in range(nscale):\n",
        "        wavelength = minWaveLength*mult**(s)\n",
        "        fo = 1.0/wavelength\n",
        "        logGabor_s = np.exp((-(np.log(radius/fo))**2) / (2 * np.log(sigmaOnf)**2))\n",
        "        logGabor_s[0,0] = 0\n",
        "        logGabor.append(logGabor_s)\n",
        "\n",
        "    spread = []\n",
        "    for o in range(norient):\n",
        "        angl = o*math.pi/norient\n",
        "        ds = sintheta * np.cos(angl) - costheta * np.sin(angl)\n",
        "        dc = costheta * np.cos(angl) + sintheta * np.sin(angl)\n",
        "        dtheta = abs(np.arctan2(ds,dc))\n",
        "        spread.append(np.exp((-dtheta**2) / (2 * thetaSigma**2)))\n",
        "\n",
        "    filter = []\n",
        "    for s in range(nscale):\n",
        "        o_list=[]\n",
        "        for o in range(norient):\n",
        "            o_list.append(logGabor[s] * spread[o])\n",
        "        filter.append(o_list)\n",
        "    return filter\n",
        "\n",
        "# @ray.remote\n",
        "def ilniqe(img, mu_pris_param, cov_pris_param, gaussian_window, principleVectors, meanOfSampleData, resize=True, block_size_h=84, block_size_w=84):\n",
        "    \"\"\"Calculate IL-NIQE (Integrated Local Natural Image Quality Evaluator) metric.\n",
        "    Ref: A Feature-Enriched Completely Blind Image Quality Evaluator.\n",
        "    This implementation could produce almost the same results as the official\n",
        "    MATLAB codes: https://github.com/milestonesvn/ILNIQE\n",
        "    Note that we do not include block overlap height and width, since they are\n",
        "    always 0 in the official implementation.\n",
        "    Args:\n",
        "        img (ndarray): Input image whose quality needs to be computed. The\n",
        "            image must be a gray or Y (of YCbCr) image with shape (h, w).\n",
        "            Range [0, 255] with float type.\n",
        "        mu_pris_param (ndarray): Mean of a pre-defined multivariate Gaussian\n",
        "            model calculated on the pristine dataset.\n",
        "        cov_pris_param (ndarray): Covariance of a pre-defined multivariate\n",
        "            Gaussian model calculated on the pristine dataset.\n",
        "        gaussian_window (ndarray): A 7x7 Gaussian window used for smoothing the\n",
        "            image.\n",
        "        principleVectors (ndarray): Features from official .mat file.\n",
        "        meanOfSampleData (ndarray): Features from official .mat file.\n",
        "        block_size_h (int): Height of the blocks in to which image is divided.\n",
        "            Default: 84 (the official recommended value).\n",
        "        block_size_w (int): Width of the blocks in to which image is divided.\n",
        "            Default: 84 (the official recommended value).\n",
        "    \"\"\"\n",
        "    assert img.ndim == 3, ('Input image must be a color image with shape (h, w, c).')\n",
        "    # crop image\n",
        "    # img = img.astype(np.float64)\n",
        "    blockrowoverlap = 0\n",
        "    blockcoloverlap = 0\n",
        "    sigmaForGauDerivative = 1.66\n",
        "    KforLog = 0.00001\n",
        "    normalizedWidth = 524\n",
        "    minWaveLength = 2.4\n",
        "    sigmaOnf = 0.55\n",
        "    mult = 1.31\n",
        "    dThetaOnSigma = 1.10\n",
        "    scaleFactorForLoG = 0.87\n",
        "    scaleFactorForGaussianDer = 0.28\n",
        "    sigmaForDownsample = 0.9\n",
        "\n",
        "    infConst = 10000\n",
        "    nanConst = 2000\n",
        "\n",
        "    if resize:\n",
        "        # img = cv2.resize(img, (normalizedWidth, normalizedWidth), interpolation=cv2.INTER_AREA)\n",
        "        resize_func = MATLABLikeResize(output_shape=(normalizedWidth, normalizedWidth))\n",
        "        img = resize_func.resize_img(img)\n",
        "        img = np.clip(img, 0.0, 255.0)\n",
        "\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    num_block_h = math.floor(h / block_size_h)\n",
        "    num_block_w = math.floor(w / block_size_w)\n",
        "    img = img[0:num_block_h * block_size_h, 0:num_block_w * block_size_w]\n",
        "\n",
        "    O1 = 0.3*img[:,:,0] + 0.04*img[:,:,1] - 0.35*img[:,:,2]\n",
        "    O2 = 0.34*img[:,:,0] - 0.6*img[:,:,1] + 0.17*img[:,:,2]\n",
        "    O3 = 0.06*img[:,:,0] + 0.63*img[:,:,1] + 0.27*img[:,:,2]\n",
        "\n",
        "    RChannel = img[:,:,0]\n",
        "    GChannel = img[:,:,1]\n",
        "    BChannel = img[:,:,2]\n",
        "\n",
        "    distparam = []  # dist param is actually the multiscale features\n",
        "    for scale in (1, 2):  # perform on two scales (1, 2)\n",
        "        mu = convolve(O3, gaussian_window, mode='nearest')\n",
        "        sigma = np.sqrt(np.abs(convolve(np.square(O3), gaussian_window, mode='nearest') - np.square(mu)))\n",
        "        # normalize, as in Eq. 1 in the paper\n",
        "        structdis = (O3 - mu) / (sigma + 1)\n",
        "\n",
        "        dx, dy = gauDerivative(sigmaForGauDerivative/(scale**scaleFactorForGaussianDer));\n",
        "        compRes = conv2(O1, dx + 1j*dy, 'same')\n",
        "        IxO1 = np.real(compRes)\n",
        "        IyO1 = np.imag(compRes)\n",
        "        GMO1 = np.sqrt(IxO1**2 + IyO1**2) + np.finfo(O1.dtype).eps\n",
        "\n",
        "        compRes = conv2(O2, dx + 1j*dy, 'same')\n",
        "        IxO2 = np.real(compRes)\n",
        "        IyO2 = np.imag(compRes)\n",
        "        GMO2 = np.sqrt(IxO2**2 + IyO2**2) + np.finfo(O2.dtype).eps\n",
        "\n",
        "        compRes = conv2(O3, dx + 1j*dy, 'same')\n",
        "        IxO3 = np.real(compRes)\n",
        "        IyO3 = np.imag(compRes)\n",
        "        GMO3 = np.sqrt(IxO3**2 + IyO3**2) + np.finfo(O3.dtype).eps\n",
        "\n",
        "        logR = np.log(RChannel + KforLog)\n",
        "        logG = np.log(GChannel + KforLog)\n",
        "        logB = np.log(BChannel + KforLog)\n",
        "        logRMS = logR - np.mean(logR)\n",
        "        logGMS = logG - np.mean(logG)\n",
        "        logBMS = logB - np.mean(logB)\n",
        "\n",
        "        Intensity = (logRMS + logGMS + logBMS) / np.sqrt(3)\n",
        "        BY = (logRMS + logGMS - 2 * logBMS) / np.sqrt(6)\n",
        "        RG = (logRMS - logGMS) / np.sqrt(2)\n",
        "\n",
        "        compositeMat = [structdis, GMO1, GMO2, GMO3, Intensity, BY, RG, IxO1, IyO1, IxO2, IyO2, IxO3, IyO3]\n",
        "\n",
        "        h, w = O3.shape\n",
        "\n",
        "        LGFilters = logGabors(h,w,minWaveLength/(scale**scaleFactorForLoG),sigmaOnf,mult,dThetaOnSigma)\n",
        "        fftIm = np.fft.fft2(O3)\n",
        "\n",
        "        logResponse = []\n",
        "        partialDer = []\n",
        "        GM = []\n",
        "        for scaleIndex in range(3):\n",
        "            for oriIndex in range(4):\n",
        "                response = np.fft.ifft2(LGFilters[scaleIndex][oriIndex]*fftIm)\n",
        "                realRes = np.real(response)\n",
        "                imagRes = np.imag(response)\n",
        "\n",
        "                compRes = conv2(realRes, dx + 1j*dy, 'same')\n",
        "                partialXReal = np.real(compRes)\n",
        "                partialYReal = np.imag(compRes)\n",
        "                realGM = np.sqrt(partialXReal**2 + partialYReal**2) + np.finfo(partialXReal.dtype).eps\n",
        "                compRes = conv2(imagRes, dx + 1j*dy, 'same')\n",
        "                partialXImag = np.real(compRes)\n",
        "                partialYImag = np.imag(compRes)\n",
        "                imagGM = np.sqrt(partialXImag**2 + partialYImag**2) + np.finfo(partialXImag.dtype).eps\n",
        "\n",
        "                logResponse.append(realRes)\n",
        "                logResponse.append(imagRes)\n",
        "                partialDer.append(partialXReal)\n",
        "                partialDer.append(partialYReal)\n",
        "                partialDer.append(partialXImag)\n",
        "                partialDer.append(partialYImag)\n",
        "                GM.append(realGM)\n",
        "                GM.append(imagGM)\n",
        "\n",
        "        compositeMat.extend(logResponse)\n",
        "        compositeMat.extend(partialDer)\n",
        "        compositeMat.extend(GM)\n",
        "\n",
        "        feat = []\n",
        "        for idx_w in range(num_block_w):\n",
        "            for idx_h in range(num_block_h):\n",
        "                # process each block\n",
        "                block_posi = [idx_h * block_size_h // scale, (idx_h + 1) * block_size_h // scale,\n",
        "                                      idx_w * block_size_w // scale, (idx_w + 1) * block_size_w // scale]\n",
        "                feat.append(compute_feature(compositeMat, block_posi))\n",
        "\n",
        "        distparam.append(np.array(feat))\n",
        "        gauForDS = matlab_fspecial([math.ceil(6*sigmaForDownsample), math.ceil(6*sigmaForDownsample)], sigmaForDownsample)\n",
        "        filterResult = convolve(O1, gauForDS, mode='nearest')\n",
        "        O1 = filterResult[0::2,0::2]\n",
        "        filterResult = convolve(O2, gauForDS, mode='nearest')\n",
        "        O2 = filterResult[0::2,0::2]\n",
        "        filterResult = convolve(O3, gauForDS, mode='nearest')\n",
        "        O3 = filterResult[0::2,0::2]\n",
        "\n",
        "        filterResult = convolve(RChannel, gauForDS, mode='nearest')\n",
        "        RChannel = filterResult[0::2,0::2]\n",
        "        filterResult = convolve(GChannel, gauForDS, mode='nearest')\n",
        "        GChannel = filterResult[0::2,0::2]\n",
        "        filterResult = convolve(BChannel, gauForDS, mode='nearest')\n",
        "        BChannel = filterResult[0::2,0::2]\n",
        "\n",
        "    distparam = np.concatenate(distparam, axis=1)\n",
        "    distparam = np.array(distparam)\n",
        "\n",
        "    # fit a MVG (multivariate Gaussian) model to distorted patch features\n",
        "    distparam[distparam>infConst] = infConst\n",
        "    meanMatrix = np.tile(meanOfSampleData,(1,distparam.shape[0]))\n",
        "    coefficientsViaPCA = np.matmul(principleVectors.T, (distparam.T - meanMatrix))\n",
        "\n",
        "    final_features = coefficientsViaPCA.T\n",
        "    mu_distparam = np.nanmean(final_features, axis=0)\n",
        "    mu_distparam[np.isnan(mu_distparam)] = nanConst\n",
        "    # use nancov. ref: https://ww2.mathworks.cn/help/stats/nancov.html\n",
        "    distparam_no_nan = final_features[~np.isnan(final_features).any(axis=1)]\n",
        "    cov_distparam = np.cov(distparam_no_nan, rowvar=False)\n",
        "    # compute niqe quality, Eq. 10 in NIQE\n",
        "    invcov_param = np.linalg.pinv((cov_pris_param + cov_distparam) / 2)\n",
        "\n",
        "    dist = []\n",
        "    for data_i in range(final_features.shape[0]):\n",
        "        currentFea = final_features[data_i,:]\n",
        "        currentFea = np.where(np.isnan(currentFea), mu_distparam, currentFea)\n",
        "        currentFea = np.expand_dims(currentFea, axis=0)\n",
        "        quality = np.matmul(\n",
        "            np.matmul((currentFea - mu_pris_param), invcov_param), np.transpose((currentFea - mu_pris_param)))\n",
        "        dist.append(np.sqrt(quality))\n",
        "    score = np.mean(np.array(dist))\n",
        "    return score\n",
        "\n",
        "def calculate_ilniqe(img, crop_border, input_order='HWC', num_cpus=3, resize=True, version='python', **kwargs):\n",
        "    \"\"\"Calculate IL-NIQE (Integrated Local Natural Image Quality Evaluator) metric.\n",
        "    Args:\n",
        "        img (ndarray): Input image whose quality needs to be computed.\n",
        "            The input image must be in range [0, 255] with float/int type in RGB space.\n",
        "            The input_order of image can be 'HWC' or 'CHW'. (BGR order)\n",
        "            If the input order is 'HWC' or 'CHW', it will be reorder to 'HWC'.\n",
        "        crop_border (int): Cropped pixels in each edge of an image. These\n",
        "            pixels are not involved in the metric calculation.\n",
        "        input_order (str): Whether the input order is 'HW', 'HWC' or 'CHW'.\n",
        "            Default: 'HWC'.\n",
        "    Returns:\n",
        "        float: IL-NIQE result.\n",
        "    \"\"\"\n",
        "\n",
        "    # we use the official params estimated from the pristine dataset.\n",
        "    gaussian_window = matlab_fspecial((5,5),5/6)\n",
        "    gaussian_window = gaussian_window/np.sum(gaussian_window)\n",
        "\n",
        "    if version == 'python':\n",
        "        # Trained using python code\n",
        "        temp_dir = tempfile.TemporaryDirectory()\n",
        "        temp_dir_path = temp_dir.name\n",
        "\n",
        "        # Download the file from `url` and save it in a temporal folder:\n",
        "        urllib.request.urlretrieve(\"https://raw.githubusercontent.com/IceClear/IL-NIQE/81de83e6faf0f47a8be04f58a0685d5f95ac0c52/python_templateModel.mat\",\n",
        "                                os.path.join(temp_dir_path,\"python_templateModel.mat\"))\n",
        "\n",
        "        model_mat = scipy.io.loadmat(os.path.join(temp_dir_path,'python_templateModel.mat'))\n",
        "    else:\n",
        "        # Trained using official Matlab\n",
        "        temp_dir = tempfile.TemporaryDirectory()\n",
        "        temp_dir_path = temp_dir.name\n",
        "\n",
        "        # Download the file from `url` and save it in a temporal folder:\n",
        "        urllib.request.urlretrieve(\"https://raw.githubusercontent.com/IceClear/IL-NIQE/81de83e6faf0f47a8be04f58a0685d5f95ac0c52/templateModel.mat\",\n",
        "                                os.path.join(temp_dir_path,\"templateModel.mat\"))\n",
        "\n",
        "        model_mat = scipy.io.loadmat(os.path.join(temp_dir_path,'templateModel.mat'))\n",
        "\n",
        "    mu_pris_param = model_mat['templateModel'][0][0]\n",
        "    cov_pris_param = model_mat['templateModel'][0][1]\n",
        "    meanOfSampleData = model_mat['templateModel'][0][2]\n",
        "    principleVectors = model_mat['templateModel'][0][3]\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.astype(np.float64)\n",
        "\n",
        "    if input_order != 'HW':\n",
        "        img = reorder_image(img, input_order=input_order)\n",
        "        img = np.squeeze(img)\n",
        "\n",
        "    assert img.shape[2] == 3 # only for RGB image\n",
        "\n",
        "    if crop_border != 0:\n",
        "        img = img[crop_border:-crop_border, crop_border:-crop_border]\n",
        "\n",
        "    # round is necessary for being consistent with MATLAB's result\n",
        "    img = img.round()\n",
        "\n",
        "    # ray.init(num_cpus=num_cpus)\n",
        "    # task_id = ilniqe.remote(img, mu_pris_param, cov_pris_param, gaussian_window, principleVectors, meanOfSampleData)\n",
        "    # ilniqe_result = ray.get(task_id)\n",
        "\n",
        "    ilniqe_result = ilniqe(img, mu_pris_param, cov_pris_param, gaussian_window, principleVectors, meanOfSampleData, resize)\n",
        "\n",
        "    if isinstance(ilniqe_result, complex) and ilniqe_result.imag == 0:\n",
        "        ilniqe_result = ilniqe_result.real\n",
        "\n",
        "    return ilniqe_result\n",
        "\n",
        "def process_images(data, is_dir=False, torch_output=True):\n",
        "    if isinstance(data, list):\n",
        "        processed_data = []\n",
        "        processed_data_3C = []\n",
        "        for img in data:\n",
        "\n",
        "            aux_img = img.astype(np.float32)\n",
        "            if torch_output:\n",
        "                aux_img = torch.from_numpy(aux_img)\n",
        "\n",
        "\n",
        "            if len(img.shape) == 3:\n",
        "                # If data has 3 dimenstions, it already has a channel dimension, add a batch dimension\n",
        "                aux_img = aux_img[None, :, :, :]\n",
        "\n",
        "                # First dimension is batch size, let's see which dimension is the channel dimension\n",
        "                # We assume the channel dimension is the one with the minimum size\n",
        "                channel_value = min(aux_img.shape[1:])\n",
        "                channel_axis = aux_img.shape.index(channel_value)\n",
        "\n",
        "                assert channel_value == 1, f\"Channel dimension {channel_value} should be 1.\"\n",
        "\n",
        "                # We will move the channel axis to the second position, if it is not already there\n",
        "                if torch_output:\n",
        "                    torch.moveaxis(aux_img, channel_axis, 1)\n",
        "                else:\n",
        "                    np.moveaxis(aux_img, channel_axis, 1)\n",
        "\n",
        "            elif len(img.shape) == 2:\n",
        "                # If data has 2 dimenstions, add a channel and batch dimension\n",
        "                aux_img = aux_img[None, None, :, :]\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported data shape for single image.\")\n",
        "\n",
        "            processed_data.append(aux_img)\n",
        "\n",
        "            if torch_output:\n",
        "                aux_img_3C = torch.cat([aux_img, aux_img, aux_img], dim=1)\n",
        "            else:\n",
        "                aux_img_3C = np.concatenate([aux_img, aux_img, aux_img], axis=1)\n",
        "            processed_data_3C.append(aux_img_3C)\n",
        "\n",
        "    elif isinstance(data, np.ndarray):\n",
        "\n",
        "        aux_img = data.astype(np.float32)\n",
        "        if torch_output:\n",
        "            aux_img = torch.from_numpy(aux_img)\n",
        "\n",
        "        # Check if it is a single image or a batch of images\n",
        "        if is_dir:\n",
        "            if len(data.shape) == 3:\n",
        "                # If data has 3 dimenstions, add a channel dimension\n",
        "                aux_img = aux_img[:, None, :, :]\n",
        "            elif len(data.shape) == 4:\n",
        "                # If data has 4 dimensions, it is a batch of images that already has a channel dimension\n",
        "                pass\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported data shape for batch of images.\")\n",
        "        else:\n",
        "            if len(data.shape) == 3:\n",
        "                # If data has 3 dimenstions, it already has a channel dimension, add a batch dimension\n",
        "                aux_img = aux_img[None, :, :, :]\n",
        "            elif len(data.shape) == 2:\n",
        "                # If data has 2 dimenstions, add a channel and batch dimension\n",
        "                aux_img = aux_img[None, None, :, :]\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported data shape for single image.\")\n",
        "\n",
        "        # First dimension is batch size, let's see which dimension is the channel dimension\n",
        "        # We assume the channel dimension is the one with the minimum size\n",
        "        channel_value = min(aux_img.shape[1:])\n",
        "        channel_axis = aux_img.shape.index(channel_value)\n",
        "\n",
        "        assert channel_value == 1, f\"Channel dimension {channel_value} should be 1.\"\n",
        "\n",
        "        # We will move the channel axis to the second position, if it is not already there\n",
        "        if torch_output:\n",
        "            processed_data = torch.moveaxis(aux_img, channel_axis, 1)\n",
        "            processed_data_3C = torch.cat([processed_data,processed_data,processed_data], dim=1)\n",
        "        else:\n",
        "            processed_data= np.moveaxis(aux_img, channel_axis, 1)\n",
        "            processed_data_3C = np.concatenate([processed_data,processed_data,processed_data], axis=1)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported data type. Expected list or np.ndarray.\")\n",
        "\n",
        "    return processed_data, processed_data_3C\n",
        "\n",
        "def calculate_metric(metric_func, gt_image, pred_image, detach=False, are_dir=False, non_reference=False):\n",
        "    if are_dir:\n",
        "\n",
        "        metric_value_list = []\n",
        "        for i in tqdm(range(len(gt_image)), desc=\"Images processed\"):\n",
        "\n",
        "            aux_gt_image = gt_image[i]\n",
        "            aux_pred_image = pred_image[i] if not non_reference else None\n",
        "\n",
        "            if isinstance(aux_gt_image, torch.Tensor):\n",
        "                aux_gt_image = aux_gt_image[None, :, :, :]\n",
        "                aux_pred_image = aux_pred_image[None, :, :, :] if not non_reference else None\n",
        "\n",
        "            try:\n",
        "                if non_reference:\n",
        "                    metric_value = metric_func(aux_gt_image)\n",
        "                else:\n",
        "                    metric_value = metric_func(aux_gt_image, aux_pred_image)\n",
        "\n",
        "                if detach:\n",
        "                    metric_value = metric_value.detach().cpu().numpy()\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing image {i}: {e}\")\n",
        "                metric_value = np.nan\n",
        "\n",
        "            metric_value_list.append(metric_value)\n",
        "        metric_value = np.array(metric_value_list)\n",
        "    else:\n",
        "        try:\n",
        "            if non_reference:\n",
        "                metric_value = metric_func(gt_image)\n",
        "            else:\n",
        "                metric_value = metric_func(gt_image, pred_image)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image: {e}\")\n",
        "            metric_value = np.nan\n",
        "\n",
        "        if isinstance(metric_value, torch.Tensor):\n",
        "            metric_value = metric_value.detach().cpu().numpy()\n",
        "\n",
        "    return metric_value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIosoPGuUR-i"
      },
      "source": [
        "# 2. **Initialise the Colab session**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLTpSJnaUR-i"
      },
      "source": [
        "## 2.1. **Check for GPU access**\n",
        "\n",
        "By default, the session should be using Python 3 and GPU acceleration, but it is possible to ensure that these are set properly by doing the following:\n",
        "\n",
        "<font size = 4>Go to **Runtime -> Change the Runtime type**\n",
        "\n",
        "<font size = 4>**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n",
        "\n",
        "<font size = 4>**Accelerator: GPU** *(Graphics processing unit)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jxIsdkrPUR-j"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to check if you have GPU access\n",
        "\n",
        "!if type nvidia-smi >/dev/null 2>&1; then \\\n",
        "    echo \"You have GPU access\"; nvidia-smi; \\\n",
        "    else \\\n",
        "    echo -e \"You do not have GPU access.\\nDid you change your runtime?\\nIf the runtime setting is correct then Google did not allocate a GPU for your session\\nExpect slow performance. To access GPU try reconnecting later\"; fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXB3TYYeUR-m"
      },
      "source": [
        "## 2.2. **Mount your Google Drive**\n",
        "\n",
        "<font size = 4> To use this notebook on the data present in your Google Drive, you need to mount your Google Drive to this notebook.\n",
        "\n",
        "<font size = 4> Play the cell below to mount your Google Drive and follow the instructions.\n",
        "\n",
        "<font size = 4> Once this is done, your data are available in the **Files** tab on the top left of notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-4L2iA4dUR-n"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to connect your Google Drive to Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNhCAcCrUR-p"
      },
      "source": [
        "# 3. **Select your parameters and paths**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. **[Optional] Download some example dataset**"
      ],
      "metadata": {
        "id": "hUnoWWsyE4Df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Choose the model´s predictions you want to download\n",
        "\n",
        "# Download the dataset\n",
        "!wget https://github.com/IvanHCenalmor/SISR_Benchmark/releases/download/0.0.1/ER_test_data.zip -O ER_test_data.zip\n",
        "!mkdir ER_test_data\n",
        "!unzip -o ER_test_data.zip -d ER_test_data\n",
        "!rm ER_test_data.zip\n",
        "\n",
        "\n",
        "model = \"UNet\" # @param [\"UNet\", \"RCAN\", \"WDSR\"]\n",
        "\n",
        "# Download the predictions from the models\n",
        "!wget https://github.com/IvanHCenalmor/SISR_Benchmark/releases/download/0.0.1/ER_{model}_Predictions.zip -O Model_Predictions.zip\n",
        "!mkdir Model_Predictions\n",
        "!unzip -o Model_Predictions.zip -d Model_Predictions\n",
        "!rm Model_Predictions.zip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AT9_D8KfE3ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGpt5hLoUR-p"
      },
      "source": [
        "## 3.2. **Setting the main parameters**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ENy9o188UR-q"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Path to ground truth and predicted images:\n",
        "#@markdown > *NOTICE*: It can be a folder or a single image.\n",
        "\n",
        "Ground_truth_path = \"/content/ER_test_data/test_gt\" #@param {type:\"string\"}\n",
        "Prediction_path = \"/content/Model_Predictions\" #@param {type:\"string\"}\n",
        "\n",
        "normalization = \"Per image\" # @param [\"None\", \"Per image\", \"Across all images\"]\n",
        "\n",
        "#####\n",
        "\n",
        "gt_is_dir = os.path.isdir(Ground_truth_path)\n",
        "pred_is_dir = os.path.isdir(Prediction_path)\n",
        "\n",
        "if gt_is_dir and pred_is_dir:\n",
        "    are_dir = True\n",
        "elif not gt_is_dir and not pred_is_dir:\n",
        "    are_dir = False\n",
        "else:\n",
        "    raise ValueError(\"Both paths should be either directories or files.\")\n",
        "\n",
        "#####\n",
        "\n",
        "# Load the ground truth images and the predicted images\n",
        "ground_truth_image, ground_truth_filename = load_images(Ground_truth_path, normalize=normalization)\n",
        "predicted_image, predicted_filename = load_images(Prediction_path, normalize=normalization)\n",
        "\n",
        "# Print image info\n",
        "print_img_info(ground_truth_image, description=\"[Raw] Ground truth image:\", is_dir=are_dir)\n",
        "print_img_info(predicted_image, description=\"[Raw] Predicted image:\", is_dir=are_dir)\n",
        "print(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "# # Process the images into as Numpy format\n",
        "# numpy_ground_truth_image, numpy_ground_truth_image_3c = process_images(ground_truth_image, is_dir=are_dir, torch_output=False)\n",
        "# numpy_predicted_image, numpy_predicted_image_3c = process_images(predicted_image, is_dir=are_dir, torch_output=False)\n",
        "\n",
        "# print_img_info(numpy_ground_truth_image, description=\"[Processed - NumPy] Ground truth image:\", is_dir=are_dir)\n",
        "# print_img_info(numpy_ground_truth_image_3c, description=\"[Processed - NumPy] Ground truth image (3 channels):\", is_dir=are_dir)\n",
        "# print_img_info(numpy_predicted_image, description=\"[Processed - NumPy] Predicted image:\", is_dir=are_dir)\n",
        "# print_img_info(numpy_predicted_image_3c, description=\"[Processed - NumPy] Predicted image (3 channels):\", is_dir=are_dir)\n",
        "# print(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "# Convert into PyTorch format for some metric calculations\n",
        "torch_ground_truth_image, torch_ground_truth_image_3c = process_images(ground_truth_image, is_dir=are_dir, torch_output=True)\n",
        "torch_predicted_image, torch_predicted_image_3c = process_images(predicted_image, is_dir=are_dir, torch_output=True)\n",
        "\n",
        "print_img_info(torch_ground_truth_image, description=\"[Processed - PyTorch] Ground truth image:\", is_dir=are_dir)\n",
        "print_img_info(torch_ground_truth_image_3c, description=\"[Processed - PyTorch] Ground truth image (3 channels):\", is_dir=are_dir)\n",
        "print_img_info(torch_predicted_image, description=\"[Processed - PyTorch] Predicted image:\", is_dir=are_dir)\n",
        "print_img_info(torch_predicted_image_3c, description=\"[Processed - PyTorch] Predicted image (3 channels):\", is_dir=are_dir)\n",
        "print(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "#####\n",
        "\n",
        "# Plot images\n",
        "if are_dir:\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(ground_truth_image[0], 'inferno')\n",
        "    ax[0].set_title(\"Real image (first image in folder)\")\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(predicted_image[0], 'inferno')\n",
        "    ax[1].set_title(\"Predicted image (first image in folder)\")\n",
        "    ax[1].axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(ground_truth_image, 'inferno')\n",
        "    ax[0].set_title(\"Real image\")\n",
        "    ax[0].axis('off')\n",
        "    ax[1].imshow(predicted_image, 'inferno')\n",
        "    ax[1].set_title(\"Predicted image\")\n",
        "    ax[1].axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfDaGJ3EUR-r"
      },
      "source": [
        "# 4. **Calculate the metrics**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYIrqWa-UR-s"
      },
      "source": [
        "## 4.1. **Mean Squared Errror (MSE)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iD56yT6FUR-s"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Calculate MSE\n",
        "\n",
        "MSE = MeanSquaredError()\n",
        "\n",
        "print(\"Calculating MSE...\")\n",
        "mse_value = calculate_metric(MSE, torch_ground_truth_image, torch_predicted_image, are_dir=are_dir, detach=False)\n",
        "print(f\"MSE: {mse_value.mean()} ± {mse_value.std()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IDwPx1lUR-s"
      },
      "source": [
        "## 4.2. **Mean Absolute Error (MAE)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5-QkqH9RUR-s"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Calculate MAE\n",
        "\n",
        "MAE = MeanAbsoluteError()\n",
        "\n",
        "print(\"Calculating MAE...\")\n",
        "mae_value = calculate_metric(MAE, torch_ground_truth_image, torch_predicted_image, are_dir=are_dir, detach=False)\n",
        "print(f\"MAE: {mae_value.mean()} ± {mae_value.std()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4lEQoTyUR-t"
      },
      "source": [
        "## 4.3. **Peak Signal to Noise Ratio (PSNR)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4QRMz0InUR-t"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Calculate PSNR\n",
        "\n",
        "PSNR = PeakSignalNoiseRatio()\n",
        "\n",
        "print(\"Calculating PSNR...\")\n",
        "psnr_value = calculate_metric(PSNR, torch_ground_truth_image, torch_predicted_image, are_dir=are_dir, detach=False)\n",
        "print(f\"PSNR: {psnr_value.mean()} ± {psnr_value.std()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66zRhNnQUR-t"
      },
      "source": [
        "## 4.4. **Structural Similarity Index Measure (SSIM)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wBFro7TzUR-u"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Calculate SSIM\n",
        "\n",
        "SSIM = StructuralSimilarityIndexMeasure()\n",
        "\n",
        "print(\"Calculating SSIM...\")\n",
        "ssim_value_array = calculate_metric(SSIM, torch_ground_truth_image, torch_predicted_image,  are_dir=are_dir, detach=False)\n",
        "print(f\"SSIM: {ssim_value_array.mean()} ± {ssim_value_array.std()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgRz34KbUR-u"
      },
      "source": [
        "## 4.5. **Learned Perceptual Image Patch Similarity with AlexNet (LPIPS-Alex)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Qs3fO5o5UR-u"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Calculate LPIPS-Alex\n",
        "\n",
        "LPIPS_ALEX = LearnedPerceptualImagePatchSimilarity(net_type='alex')\n",
        "\n",
        "print(\"Calculating LPIPS-Alex...\")\n",
        "lpips_alex_value = calculate_metric(LPIPS_ALEX, torch_ground_truth_image_3c, torch_predicted_image_3c,  are_dir=are_dir, detach=True)\n",
        "print(f\"LPIPS-Alex: {lpips_alex_value.mean()} ± {lpips_alex_value.std()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3HEF1hLUR-u"
      },
      "source": [
        "## 4.5. **Learned Perceptual Image Patch Similarity with VGG-16 (LPIPS-VGG)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aeg2mDF5UR-v"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Calculate LPIPS-VGG\n",
        "\n",
        "LPIPS_VGG = LearnedPerceptualImagePatchSimilarity(net_type='vgg')\n",
        "\n",
        "print(\"Calculating LPIPS-VGG...\")\n",
        "lpips_vgg_value = calculate_metric(LPIPS_VGG, torch_ground_truth_image_3c, torch_predicted_image_3c,  are_dir=are_dir, detach=True)\n",
        "print(f\"LPIPS-VGG: {lpips_vgg_value.mean()} ± {lpips_vgg_value.std()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhZ0MWTNUR-v"
      },
      "source": [
        "## 4.6. **Integrated Local Natural Image Quality Evaluator (IL-NIQE)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Scs9QxU2UR-v"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Calculate IL-NIQE\n",
        "\n",
        "from skimage.util import img_as_ubyte\n",
        "def ilnique_function(crop_border=0, input_order='HW', resize=True, version='python', **kwargs):\n",
        "\n",
        "    def aux_function (images):\n",
        "        return calculate_ilniqe(images,\n",
        "                                crop_border=crop_border,\n",
        "                                input_order=input_order,\n",
        "                                resize=resize,\n",
        "                                version=version)\n",
        "\n",
        "    return aux_function\n",
        "\n",
        "# Check the input order of the image\n",
        "if len(ground_truth_image.shape) == 2:\n",
        "    input_order='HW'\n",
        "elif len(ground_truth_image.shape) == 3 and are_dir:\n",
        "    input_order='HW'\n",
        "elif (len(ground_truth_image.shape) == 3 and not are_dir):\n",
        "    # We assume the channel dimension is the one with the minimum size\n",
        "    channel_value = min(ground_truth_image.shape)\n",
        "    channel_axis = ground_truth_image.shape.index(channel_value)\n",
        "\n",
        "    assert channel_value == 3, f\"Channel dimension {channel_value} should be 1.\"\n",
        "\n",
        "    if channel_axis == 0:\n",
        "        input_order='CHW'\n",
        "    elif channel_axis == 2:\n",
        "        input_order='HWC'\n",
        "\n",
        "elif len(ground_truth_image.shape) == 4:\n",
        "    # We assume the channel dimension is the one with the minimum size\n",
        "    channel_value = min(ground_truth_image.shape[1:])\n",
        "    channel_axis = ground_truth_image.shape.index(channel_value)\n",
        "\n",
        "    assert channel_value == 3, f\"Channel dimension {channel_value} should be 1.\"\n",
        "\n",
        "    if channel_axis == 1:\n",
        "        input_order='CHW'\n",
        "    elif channel_axis == 3:\n",
        "        input_order='HWC'\n",
        "\n",
        "print(\"Calculating IL-NIQE for the ground truth images...\")\n",
        "ilniqe_gt_value = calculate_metric(ilnique_function(input_order=input_order), img_as_ubyte(ground_truth_image), None, are_dir=are_dir, detach=False, non_reference=True)\n",
        "print(f\"IL-NIQE (ground truth): {ilniqe_gt_value.mean()} ± {ilniqe_gt_value.std()}\")\n",
        "print(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "print(\"Calculating IL-NIQE for the predicted images...\")\n",
        "ilniqe_pred_value = calculate_metric(ilnique_function(input_order=input_order),  img_as_ubyte(predicted_image), None, are_dir=are_dir, detach=False, non_reference=True)\n",
        "print(f\"IL-NIQE (prediction): {ilniqe_pred_value.mean()} ± {ilniqe_pred_value.std()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWMAt4IEUR-v"
      },
      "source": [
        "## 4.7. **Decorrelation analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pTtsTDyvUR-v"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Calculate decorrelation analysis\n",
        "\n",
        "DECORR_ANALYSIS = DecorrAnalysis()\n",
        "\n",
        "def decorrelation_analysis_function(DECORR_ANALYSIS, plot_analysis=False):\n",
        "\n",
        "    def aux_function (images):\n",
        "        DECORR_ANALYSIS.run_analysis(images)\n",
        "        if plot_analysis:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.title(\"Decorrelation Analysis\")\n",
        "            plt.imshow(DECORR_ANALYSIS.plot_results())\n",
        "            plt.axis(\"off\")\n",
        "            plt.show();\n",
        "\n",
        "        return DECORR_ANALYSIS.resolution\n",
        "\n",
        "    return aux_function\n",
        "\n",
        "plot_analysis = False #@param {type:\"boolean\"}\n",
        "\n",
        "print(\"Calculating DECORR_ANALYSIS for the ground truth images...\")\n",
        "decorrelation_gt_value = calculate_metric(decorrelation_analysis_function(DECORR_ANALYSIS, plot_analysis=plot_analysis), ground_truth_image, None, are_dir=are_dir, detach=False, non_reference=True)\n",
        "print(f\"DECORR_ANALYSIS (ground truth): {ground_truth_image.mean()} ± {ground_truth_image.std()}\")\n",
        "print(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "print(\"Calculating DECORR_ANALYSIS for the predicted images...\")\n",
        "decorrelation_pred_value = calculate_metric(decorrelation_analysis_function(DECORR_ANALYSIS, plot_analysis=plot_analysis), predicted_image, None, are_dir=are_dir, detach=False, non_reference=True)\n",
        "print(f\"DECORR_ANALYSIS (prediction): {predicted_image.mean()} ± {predicted_image.std()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgfz4oHuUR-v"
      },
      "source": [
        "## 4.8. **SQUIRREL Error Map - RSP and RSE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "0Kl3IyaBUR-w"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Calculate error map\n",
        "\n",
        "# We need the low resolution images to calculate the error map\n",
        "low_res_path = \"/content/ER_test_data/test_wf\" # @param {type:\"string\"}\n",
        "\n",
        "# Load the widefield images\n",
        "low_res_images, _ = load_images(low_res_path, normalize=normalization)\n",
        "\n",
        "print_img_info(low_res_images, description=\"Low resolution image:\", is_dir=are_dir)\n",
        "\n",
        "def calculate_error_map(low_res_images, predicted_image, are_dir=False, plot_analysis=False):\n",
        "    ERROR_MAP = ErrorMap()\n",
        "\n",
        "    if are_dir:\n",
        "        rse_values = []\n",
        "        rsp_values = []\n",
        "\n",
        "        for low_res, pred in tqdm(zip(low_res_images, predicted_image), desc=\"Images processed\"):\n",
        "            ERROR_MAP.optimise(low_res, pred)\n",
        "\n",
        "            rse_values.append(ERROR_MAP.getRSE())\n",
        "            rsp_values.append(ERROR_MAP.getRSP())\n",
        "\n",
        "            if plot_analysis:\n",
        "                plt.figure(figsize=(10, 5))\n",
        "                plt.title(\"Error Map\")\n",
        "                plt.imshow(ERROR_MAP.plot_results())\n",
        "                plt.axis(\"off\")\n",
        "                plt.show()\n",
        "\n",
        "    else:\n",
        "        ERROR_MAP.optimise(low_res_images, predicted_image)\n",
        "        if plot_analysis:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.title(\"Error Map\")\n",
        "            plt.imshow(ERROR_MAP.plot_results())\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "        rse_values = ERROR_MAP.getRSE()\n",
        "        rsp_values = ERROR_MAP.getRSP()\n",
        "\n",
        "    return np.array(rse_values), np.array(rsp_values)\n",
        "\n",
        "plot_analysis = False #@param {type:\"boolean\"}\n",
        "\n",
        "print(\"Calculating error map for the ground truth images...\")\n",
        "rse_gt_value, rsp_gt_value = calculate_error_map(low_res_images, ground_truth_image, are_dir=are_dir, plot_analysis=plot_analysis)\n",
        "print(f\"RSE (ground truth): {rse_gt_value.mean()} ± {rse_gt_value.std()}\")\n",
        "print(f\"RSP (ground truth): {rsp_gt_value.mean()} ± {rsp_gt_value.std()}\")\n",
        "print(\"-\" * 50 + \"\\n\")\n",
        "\n",
        "print(\"Calculating error map for the predicted images...\")\n",
        "rse_pred_value, rsp_pred_value = calculate_error_map(low_res_images, predicted_image, are_dir=are_dir, plot_analysis=plot_analysis)\n",
        "print(f\"RSE (prediction): {rse_pred_value.mean()} ± {rse_pred_value.std()}\")\n",
        "print(f\"RSP (prediction): {rsp_pred_value.mean()} ± {rsp_pred_value.std()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yz_py7RUR-w"
      },
      "source": [
        "# 5. **Export the results**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6_zyQYjFUR-w"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Load the calculated metrics\n",
        "\n",
        "# Dictionary with all the possible metrics and their values\n",
        "metrics_dict = {\n",
        "    'MSE': mse_value if 'mse_value' in locals() else np.nan,\n",
        "    'MAE': mae_value if 'mae_value' in locals() else np.nan,\n",
        "    'PSNR': psnr_value if 'psnr_value' in locals() else np.nan,\n",
        "    'SSIM': ssim_value_array if 'ssim_value_array' in locals() else np.nan,\n",
        "    'LPIPS_ALEX': lpips_alex_value if 'lpips_alex_value' in locals() else np.nan,\n",
        "    'LPIPS_VGG': lpips_vgg_value if 'lpips_vgg_value' in locals() else np.nan,\n",
        "    'IL-NIQE (GT)': ilniqe_gt_value if 'ilniqe_gt_value' in locals() else np.nan,\n",
        "    'IL-NIQE (Pred)': ilniqe_pred_value if 'ilniqe_pred_value' in locals() else np.nan,\n",
        "    'DECORR_ANALYSIS (GT)': decorrelation_gt_value if 'decorrelation_gt_value' in locals() else np.nan,\n",
        "    'DECORR_ANALYSIS (Pred)': decorrelation_pred_value if 'decorrelation_pred_value' in locals() else np.nan,\n",
        "    'RSE (GT)': rse_gt_value if 'rse_gt_value' in locals() else np.nan,\n",
        "    'RSE (Pred)': rse_pred_value if 'rse_pred_value' in locals() else np.nan,\n",
        "    'RSP (GT)': rsp_gt_value if 'rsp_gt_value' in locals() else np.nan,\n",
        "    'RSP (Pred)': rsp_pred_value if 'rsp_pred_value' in locals() else np.nan,\n",
        "}\n",
        "\n",
        "mean_metrics = {k: np.nanmean(v) for k, v in metrics_dict.items()}\n",
        "std_metrics = {k: np.nanstd(v) for k, v in metrics_dict.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3R9c6R_UR-w"
      },
      "source": [
        "## 5.1. **Export the mean/std results to a CSV file**\n",
        "\n",
        "\n",
        "You need to specify the path where you want to save your results CSV file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DQm9VKdrUR-w"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame to store the mean from the metrics\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Mean': list(mean_metrics.values()),\n",
        "    'Std': list(std_metrics.values())\n",
        "})\n",
        "metrics_df.index = list(mean_metrics.keys())\n",
        "\n",
        "# Specify the path to save the CSV file\n",
        "csv_file_path = \"/content\" #@param {type:\"string\"}\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "metrics_df.to_csv(os.path.join(csv_file_path, \"metrics_average.csv\"), index=False)\n",
        "\n",
        "# Display the DataFrame\n",
        "metrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6lqV0WtUR-w"
      },
      "source": [
        "## 5.2. **Export the results per-image to a CSV file**\n",
        "\n",
        "You need to specify the path where you want to save your results CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "I2Dk51pYUR-w"
      },
      "outputs": [],
      "source": [
        "# Create a Dataframe that stores the metrics for each image\n",
        "try:\n",
        "    metrics_per_image_df = pd.DataFrame(metrics_dict)\n",
        "except: # In case is a single image\n",
        "    metrics_per_image_df = pd.DataFrame(metrics_dict, index=[0])\n",
        "metrics_per_image_df.index = ground_truth_filename if are_dir else [os.path.basename(ground_truth_filename)]\n",
        "\n",
        "# Specify the path to save the CSV file\n",
        "csv_file_path_per_image = \"/content\" #@param {type:\"string\"}\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "metrics_per_image_df.to_csv(os.path.join(csv_file_path_per_image, \"metrics_per_image.csv\"), index=False)\n",
        "\n",
        "# Show the dataframe with the metrics for each image\n",
        "metrics_per_image_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LrgUXTBgUR-x"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Visualize the results on interactive plots\n",
        "\n",
        "def create_interactive_plots_all_metrics(metrics_df, filenames):\n",
        "    \"\"\"\n",
        "    Create interactive scatter plots for all metrics in a 2xN grid.\n",
        "\n",
        "    Args:\n",
        "        metrics_df: DataFrame containing metrics for each image\n",
        "        filenames: List of image filenames\n",
        "    \"\"\"\n",
        "    # Calculate number of metrics and required subplot layout\n",
        "    n_metrics = len(metrics_df.columns)\n",
        "    n_rows = math.ceil(n_metrics / 2)\n",
        "\n",
        "    # Create figure with subplots with adjusted spacing\n",
        "    fig = make_subplots(\n",
        "        rows=n_rows, cols=2,\n",
        "        subplot_titles=[metric for metric in metrics_df.columns],\n",
        "        horizontal_spacing=0.15,\n",
        "        vertical_spacing=0.1  # Reduced from 0.2 to 0.1\n",
        "    )\n",
        "\n",
        "    # Add traces for each metric\n",
        "    for idx, metric_name in enumerate(metrics_df.columns):\n",
        "        row = idx // 2 + 1\n",
        "        col = idx % 2 + 1  # Alternate between columns 1 and 2\n",
        "\n",
        "        # Add scatter plot\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=list(range(len(metrics_df))),\n",
        "                y=metrics_df[metric_name],\n",
        "                mode='markers',\n",
        "                name=metric_name,\n",
        "                text=filenames,\n",
        "                hovertemplate=f\"{metric_name}: %{{y:.4f}}<br>Image: %{{text}}<extra></extra>\"\n",
        "            ),\n",
        "            row=row, col=col\n",
        "        )\n",
        "\n",
        "        # Update axes labels\n",
        "        fig.update_xaxes(title_text=\"Image Index\", row=row, col=col)\n",
        "        fig.update_yaxes(title_text=metric_name, row=row, col=col)\n",
        "\n",
        "    # Update layout with adjusted height\n",
        "    fig.update_layout(\n",
        "        title=\"Metrics Overview\",\n",
        "        showlegend=False,\n",
        "        height=300*n_rows,  # Reduced from 300 to 200 per row\n",
        "        width=1500,\n",
        "        template=\"plotly_white\"\n",
        "    )\n",
        "\n",
        "    # Show plot\n",
        "    fig.show()\n",
        "\n",
        "# Create plots for all metrics\n",
        "print(\"\\nCreating plots for all metrics...\")\n",
        "create_interactive_plots_all_metrics(metrics_per_image_df, ground_truth_filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "calc_metrics_11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}